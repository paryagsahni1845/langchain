{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ee0321",
   "metadata": {},
   "source": [
    "LCEL (LangChain Expression Language) is a domain-specific language in LangChain designed to simplify how developers create and manipulate prompts, chains, and outputs. It allows combining LLM calls, variables, and logic in a concise, readable syntax without writing full Python code. LCEL is useful for building complex workflows quickly, like conditional flows or multi-step reasoning, while keeping everything declarative. It improves maintainability by separating the chain logic from the code itself. Essentially, LCEL makes LangChain projects more modular, flexible, and easier to reason about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff26b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REDACTED' | Set-Content replacements.txt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0c7673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F633C12CC0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F633D56000>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", api_key=groq_api_key) \n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be884ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage , SystemMessage\n",
    "from sympy import content\n",
    "messages = [\n",
    "    SystemMessage(content=\"translate from english to french\"),\n",
    "    HumanMessage(content=\"hello how are you\")\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b701473f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Bonjour, comment vas-tu ? \\n\\n(Note: A more formal translation would be \"Bonjour, comment allez-vous ?\" but I used the informal \"tu\" since you used \"you\" in your greeting)', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 44, 'total_tokens': 88, 'completion_time': 0.186088342, 'prompt_time': 0.018046498, 'queue_time': 0.087308932, 'total_time': 0.20413484}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--9b36eef0-8f83-4715-b330-37c229949230-0', usage_metadata={'input_tokens': 44, 'output_tokens': 44, 'total_tokens': 88})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69378d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour, comment vas-tu ? \\n\\n(Note: A more formal translation would be \"Bonjour, comment allez-vous ?\" but I used the informal \"tu\" since you used \"you\" in your greeting)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7ebacb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour, comment allez-vous ?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using lcel - chain the components\n",
    "chain = llm|parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt template - convert into list of message \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"translate the following into {language}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",template),(\"user\",\"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f72c3c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='translate the following into french', additional_kwargs={}, response_metadata={}), HumanMessage(content='hello', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt.invoke({\"language\":\"french\",\"text\":\"hello\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0e4d605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='translate the following into french', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hello', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61c96418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour !'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=prompt|llm|parser\n",
    "chain.invoke({\"language\":\"french\",\"text\":\"hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671de4af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
