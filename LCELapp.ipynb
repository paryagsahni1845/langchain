{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ee0321",
   "metadata": {},
   "source": [
    "LCEL (LangChain Expression Language) is a domain-specific language in LangChain designed to simplify how developers create and manipulate prompts, chains, and outputs. It allows combining LLM calls, variables, and logic in a concise, readable syntax without writing full Python code. LCEL is useful for building complex workflows quickly, like conditional flows or multi-step reasoning, while keeping everything declarative. It improves maintainability by separating the chain logic from the code itself. Essentially, LCEL makes LangChain projects more modular, flexible, and easier to reason about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff26b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0c7673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000020A43C4E6C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000020A43D9A210>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0.7) \n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be884ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage , SystemMessage\n",
    "from sympy import content\n",
    "messages = [\n",
    "    SystemMessage(content=\"translate from english to french\"),\n",
    "    HumanMessage(content=\"hello how are you\")\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02301ab3",
   "metadata": {},
   "source": [
    "this will give response as well as metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b701473f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Bonjour, comment allez-vous ? \\n\\n(Translation: Hello, how are you?)', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 44, 'total_tokens': 62, 'completion_time': 0.048611798, 'prompt_time': 0.011297178, 'queue_time': 0.051036362, 'total_time': 0.059908976}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--1c1fab78-2678-4e2f-bc85-156a432f181b-0', usage_metadata={'input_tokens': 44, 'output_tokens': 18, 'total_tokens': 62})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69378d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour, comment allez-vous ? \\n\\n(Translation: Hello, how are you?)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e473603",
   "metadata": {},
   "source": [
    "chaining a prompt template with the LLaMA-3.3-70B model and an output parser to process the response (e.g., \"Bonjour, comment vas-tu ?\") into a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ebacb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour, comment allez-vous ?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using lcel - chain the components\n",
    "chain = llm|parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec43be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt template - convert into list of message \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"translate the following into {language}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",template),(\"user\",\"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f72c3c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='translate the following into french', additional_kwargs={}, response_metadata={}), HumanMessage(content='hello', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt.invoke({\"language\":\"french\",\"text\":\"hello\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e4d605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='translate the following into french', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hello', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61c96418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=prompt|llm|parser\n",
    "chain.invoke({\"language\":\"french\",\"text\":\"hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671de4af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
